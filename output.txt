

1) Output when using the Small frozen lake and parameters specified in the Listing 5 (assignment specification).# Model-based algorithms## Policy iterationNumber of iterations required in policy iteration is: 4Lake: [['&' '.' '.' '.'] ['.' '#' '.' '#'] ['.' '.' '.' '#'] ['#' '.' '.' '$']]Policy: [['_' '>' '_' '<'] ['_' '^' '_' '^'] ['>' '_' '_' '^'] ['^' '>' '>' '^']]Value:[[0.455 0.504 0.579 0.505] [0.508 0.    0.653 0.   ] [0.584 0.672 0.768 0.   ] [0.    0.771 0.887 1.   ]]## Value iterationNumber of iterations required in value iteration: 10Lake: [['&' '.' '.' '.'] ['.' '#' '.' '#'] ['.' '.' '.' '#'] ['#' '.' '.' '$']]Policy: [['_' '>' '_' '<'] ['_' '^' '_' '^'] ['>' '_' '_' '^'] ['^' '>' '>' '^']]Value:[[0.455 0.504 0.579 0.505] [0.508 0.    0.653 0.   ] [0.584 0.672 0.768 0.   ] [0.    0.771 0.887 1.   ]]# Model-free algorithms## Sarsaepisodes: 2000Lake: [['&' '.' '.' '.'] ['.' '#' '.' '#'] ['.' '.' '.' '#'] ['#' '.' '.' '$']]Policy: [['>' '>' '_' '<'] ['_' '^' '_' '^'] ['>' '_' '_' '^'] ['^' '>' '>' '>']]Value:[[0.408 0.464 0.552 0.405] [0.365 0.    0.641 0.   ] [0.483 0.632 0.77  0.   ] [0.    0.757 0.882 1.   ]]## Q-learningepisodes: 399Lake: [['&' '.' '.' '.'] ['.' '#' '.' '#'] ['.' '.' '.' '#'] ['#' '.' '.' '$']]Policy: [['>' '>' '_' '<'] ['^' '^' '_' '^'] ['^' '_' '_' '^'] ['^' '>' '>' '<']]Value:[[0.359 0.411 0.5   0.408] [0.336 0.    0.636 0.   ] [0.332 0.597 0.763 0.   ] [0.    0.762 0.898 1.   ]]## Linear SarsaLake: [['&' '.' '.' '.'] ['.' '#' '.' '#'] ['.' '.' '.' '#'] ['#' '.' '.' '$']]Policy: [['>' '>' '_' '<'] ['^' '^' '_' '^'] ['>' '>' '_' '^'] ['^' '>' '>' '>']]Value:[[0.445 0.498 0.575 0.469] [0.409 0.    0.653 0.   ] [0.576 0.685 0.776 0.   ] [0.    0.748 0.886 1.   ]]## Linear Q-learningLake: [['&' '.' '.' '.'] ['.' '#' '.' '#'] ['.' '.' '.' '#'] ['#' '.' '.' '$']]Policy: [['_' '<' '<' '^'] ['_' '^' '_' '^'] ['>' '>' '_' '^'] ['^' '>' '>' '_']]Value:[[0.461 0.365 0.332 0.312] [0.526 0.    0.578 0.   ] [0.589 0.676 0.771 0.   ] [0.    0.76  0.881 1.   ]]2) Output when using the Big frozen lake and parameters specified in the Listing 5 (assignment specification).# Model-based algorithms## Policy iterationNumber of iterations required in policy iteration is: 6Lake: [['&' '.' '.' '.' '.' '.' '.' '.'] ['.' '.' '.' '.' '.' '.' '.' '.'] ['.' '.' '.' '#' '.' '.' '.' '.'] ['.' '.' '.' '.' '.' '#' '.' '.'] ['.' '.' '.' '#' '.' '.' '.' '.'] ['.' '#' '#' '.' '.' '.' '#' '.'] ['.' '#' '.' '.' '#' '.' '#' '.'] ['.' '.' '.' '#' '.' '.' '.' '$']]Policy: [['>' '>' '>' '>' '>' '>' '_' '_'] ['>' '>' '>' '>' '>' '>' '_' '_'] ['>' '_' '_' '^' '>' '>' '>' '_'] ['>' '>' '>' '>' '_' '^' '>' '_'] ['^' '^' '^' '^' '>' '>' '>' '_'] ['^' '^' '^' '>' '>' '_' '^' '_'] ['_' '^' '>' '^' '^' '_' '^' '_'] ['>' '>' '^' '^' '>' '>' '>' '^']]Value:[[0.189 0.212 0.237 0.266 0.298 0.334 0.374 0.418] [0.203 0.227 0.256 0.288 0.332 0.373 0.419 0.469] [0.203 0.227 0.25  0.    0.356 0.408 0.47  0.529] [0.226 0.255 0.288 0.325 0.383 0.    0.519 0.595] [0.202 0.222 0.244 0.    0.441 0.507 0.581 0.671] [0.176 0.    0.    0.417 0.491 0.567 0.    0.756] [0.176 0.    0.301 0.354 0.    0.654 0.    0.869] [0.202 0.227 0.261 0.    0.656 0.771 0.869 1.   ]]## Value iterationNumber of iterations required in value iteration: 19Lake: [['&' '.' '.' '.' '.' '.' '.' '.'] ['.' '.' '.' '.' '.' '.' '.' '.'] ['.' '.' '.' '#' '.' '.' '.' '.'] ['.' '.' '.' '.' '.' '#' '.' '.'] ['.' '.' '.' '#' '.' '.' '.' '.'] ['.' '#' '#' '.' '.' '.' '#' '.'] ['.' '#' '.' '.' '#' '.' '#' '.'] ['.' '.' '.' '#' '.' '.' '.' '$']]Policy: [['>' '>' '>' '>' '>' '>' '_' '_'] ['>' '>' '>' '>' '>' '>' '_' '_'] ['>' '_' '_' '^' '>' '>' '>' '_'] ['>' '>' '>' '>' '_' '^' '>' '_'] ['^' '^' '^' '^' '>' '>' '>' '_'] ['^' '^' '^' '>' '>' '_' '^' '_'] ['_' '^' '>' '^' '^' '_' '^' '_'] ['>' '>' '^' '^' '>' '>' '>' '^']]Value:[[0.189 0.212 0.237 0.266 0.298 0.334 0.374 0.418] [0.203 0.227 0.256 0.288 0.332 0.373 0.419 0.469] [0.203 0.227 0.25  0.    0.356 0.408 0.47  0.529] [0.226 0.255 0.288 0.325 0.383 0.    0.519 0.595] [0.202 0.222 0.244 0.    0.441 0.507 0.581 0.671] [0.176 0.    0.    0.417 0.491 0.567 0.    0.756] [0.176 0.    0.301 0.354 0.    0.654 0.    0.869] [0.202 0.227 0.261 0.    0.656 0.771 0.869 1.   ]]# Model-free algorithms## Sarsaepisodes: 2000Lake: [['&' '.' '.' '.' '.' '.' '.' '.'] ['.' '.' '.' '.' '.' '.' '.' '.'] ['.' '.' '.' '#' '.' '.' '.' '.'] ['.' '.' '.' '.' '.' '#' '.' '.'] ['.' '.' '.' '#' '.' '.' '.' '.'] ['.' '#' '#' '.' '.' '.' '#' '.'] ['.' '#' '.' '.' '#' '.' '#' '.'] ['.' '.' '.' '#' '.' '.' '.' '$']]Policy: [['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^']]Value:[[0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.]]## Q-learningepisodes: 2000Lake: [['&' '.' '.' '.' '.' '.' '.' '.'] ['.' '.' '.' '.' '.' '.' '.' '.'] ['.' '.' '.' '#' '.' '.' '.' '.'] ['.' '.' '.' '.' '.' '#' '.' '.'] ['.' '.' '.' '#' '.' '.' '.' '.'] ['.' '#' '#' '.' '.' '.' '#' '.'] ['.' '#' '.' '.' '#' '.' '#' '.'] ['.' '.' '.' '#' '.' '.' '.' '$']]Policy: [['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^']]Value:[[0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.]]## Linear SarsaLake: [['&' '.' '.' '.' '.' '.' '.' '.'] ['.' '.' '.' '.' '.' '.' '.' '.'] ['.' '.' '.' '#' '.' '.' '.' '.'] ['.' '.' '.' '.' '.' '#' '.' '.'] ['.' '.' '.' '#' '.' '.' '.' '.'] ['.' '#' '#' '.' '.' '.' '#' '.'] ['.' '#' '.' '.' '#' '.' '#' '.'] ['.' '.' '.' '#' '.' '.' '.' '$']]Policy: [['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^']]Value:[[0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.]]## Linear Q-learningLake: [['&' '.' '.' '.' '.' '.' '.' '.'] ['.' '.' '.' '.' '.' '.' '.' '.'] ['.' '.' '.' '#' '.' '.' '.' '.'] ['.' '.' '.' '.' '.' '#' '.' '.'] ['.' '.' '.' '#' '.' '.' '.' '.'] ['.' '#' '#' '.' '.' '.' '#' '.'] ['.' '#' '.' '.' '#' '.' '#' '.'] ['.' '.' '.' '#' '.' '.' '.' '$']]Policy: [['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^'] ['^' '^' '^' '^' '^' '^' '^' '^']]Value:[[0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 0. 0. 0. 0. 0. 0.]]3) Output when using the Small frozen lake and 20,000 max episodes

# Model-based algorithms

## Policy iteration
Number of iterations required in policy iteration is: 4
Lake: 
[['&' '.' '.' '.']
 ['.' '#' '.' '#']
 ['.' '.' '.' '#']
 ['#' '.' '.' '$']]
Policy: 
[['_' '>' '_' '<']
 ['_' '^' '_' '^']
 ['>' '_' '_' '^']
 ['^' '>' '>' '^']]
Value:
[[0.455 0.504 0.579 0.505]
 [0.508 0.    0.653 0.   ]
 [0.584 0.672 0.768 0.   ]
 [0.    0.771 0.887 1.   ]]

## Value iteration
Number of iterations required in value iteration: 10
Lake: 
[['&' '.' '.' '.']
 ['.' '#' '.' '#']
 ['.' '.' '.' '#']
 ['#' '.' '.' '$']]
Policy: 
[['_' '>' '_' '<']
 ['_' '^' '_' '^']
 ['>' '_' '_' '^']
 ['^' '>' '>' '^']]
Value:
[[0.455 0.504 0.579 0.505]
 [0.508 0.    0.653 0.   ]
 [0.584 0.672 0.768 0.   ]
 [0.    0.771 0.887 1.   ]]

# Model-free algorithms

## Sarsa
episodes: 14942
Lake: 
[['&' '.' '.' '.']
 ['.' '#' '.' '#']
 ['.' '.' '.' '#']
 ['#' '.' '.' '$']]
Policy: 
[['>' '>' '_' '<']
 ['_' '^' '_' '^']
 ['>' '_' '_' '^']
 ['^' '>' '>' '^']]
Value:
[[0.411 0.498 0.524 0.405]
 [0.434 0.    0.587 0.   ]
 [0.527 0.638 0.782 0.   ]
 [0.    0.768 0.895 1.   ]]

## Q-learning
episodes: 186
Lake: 
[['&' '.' '.' '.']
 ['.' '#' '.' '#']
 ['.' '.' '.' '#']
 ['#' '.' '.' '$']]
Policy: 
[['>' '>' '_' '<']
 ['^' '^' '_' '^']
 ['>' '>' '_' '^']
 ['^' '>' '>' '>']]
Value:
[[0.468 0.532 0.601 0.409]
 [0.328 0.    0.694 0.   ]
 [0.483 0.683 0.798 0.   ]
 [0.    0.735 0.897 1.   ]]

## Linear Sarsa
Lake: 
[['&' '.' '.' '.']
 ['.' '#' '.' '#']
 ['.' '.' '.' '#']
 ['#' '.' '.' '$']]
Policy: 
[['_' '>' '_' '<']
 ['_' '^' '_' '^']
 ['>' '_' '_' '^']
 ['^' '>' '>' '^']]
Value:
[[0.449 0.504 0.566 0.433]
 [0.502 0.    0.644 0.   ]
 [0.579 0.669 0.741 0.   ]
 [0.    0.767 0.883 1.   ]]

## Linear Q-learning
Lake: 
[['&' '.' '.' '.']
 ['.' '#' '.' '#']
 ['.' '.' '.' '#']
 ['#' '.' '.' '$']]
Policy: 
[['>' '>' '_' '<']
 ['^' '^' '_' '^']
 ['>' '>' '_' '^']
 ['^' '>' '>' '^']]
Value:
[[0.452 0.512 0.584 0.506]
 [0.388 0.    0.66  0.   ]
 [0.546 0.661 0.763 0.   ]
 [0.    0.743 0.886 1.   ]]


